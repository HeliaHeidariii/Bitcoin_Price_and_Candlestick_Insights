{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install ta\n"
      ],
      "metadata": {
        "id": "El9-DmB3XUsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YldRAECCW2tz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Lambda\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import StandardScaler , MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Conv1D, LSTM, Dense, Reshape, Lambda, Dropout,BatchNormalization\n",
        "import keras.backend as K\n",
        "import ta\n",
        "\n",
        "btc_data = yf.download('BTC-USD', period='1y', interval='1d')\n",
        "\n",
        "candlestick_data = btc_data[['Open', 'High', 'Low', 'Close']]\n",
        "\n",
        "btc_data['RSI'] = ta.momentum.RSIIndicator(btc_data['Close']).rsi()\n",
        "btc_data['MACD'] = ta.trend.MACD(btc_data['Close']).macd()\n",
        "\n",
        "full_data = btc_data[['Open', 'High', 'Low', 'Close', 'RSI', 'MACD']].dropna()\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(full_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data, time_step=60, forecast_step=30):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_step - forecast_step):\n",
        "        X.append(data[i:(i + time_step), :])\n",
        "        y.append(data[(i + time_step):(i + time_step + forecast_step), :])\n",
        "    return np.array(X), np.array(y)\n",
        "time_step = 60\n",
        "forecast_step = 30\n",
        "X, y = create_dataset(scaled_data, time_step, forecast_step)\n",
        "\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n"
      ],
      "metadata": {
        "id": "_sbhjeS0XLUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(time_step, X.shape[2])))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "\n",
        "model.add(LSTM(100, return_sequences=True, recurrent_dropout=0.2))\n",
        "model.add(LSTM(100, return_sequences=True, recurrent_dropout=0.2))\n",
        "model.add(LSTM(100, return_sequences=True, recurrent_dropout=0.2))\n",
        "model.add(LSTM(50, return_sequences=True, recurrent_dropout=0.2))\n",
        "model.add(LSTM(50, return_sequences=False, recurrent_dropout=0.2))\n",
        "\n",
        "model.add(Lambda(lambda x: tf.stack([\n",
        "    tf.abs(x[..., 3] - x[..., 0]) /\n",
        "    tf.maximum(x[..., 3], x[..., 0]),  # درصد بدنه کندل (Close - Open)\n",
        "    tf.abs(x[..., 1] - x[..., 2]) /\n",
        "    tf.maximum(x[..., 1], x[..., 2])   # درصد High و Low (High - Low)\n",
        "], axis=-1)))\n",
        "\n",
        "model.add(Dense(forecast_step * X.shape[2] ))\n",
        "model.add(Reshape((forecast_step, X.shape[2])))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=64)\n"
      ],
      "metadata": {
        "id": "5N0uKQVVXLSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "qMUTGMT6OC9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_sequence = scaled_data[-time_step:]  # آخرین 60 تایم‌استپ از داده‌ها\n",
        "\n",
        "# تغییر شکل داده‌ها برای ورودی به مدل (براساس تعداد ویژگی‌ها)\n",
        "last_sequence = last_sequence.reshape((1, time_step, X.shape[2]))  # تنظیم تعداد ویژگی‌ها\n",
        "\n",
        "predicted_data = model.predict(last_sequence)  # پیش‌بینی داده‌ها\n",
        "\n",
        "# تبدیل خروجی به پیش‌بینی برای 30 روز آینده (براساس ویژگی‌های انتخاب شده)\n",
        "predicted_data = predicted_data.reshape(-1, X.shape[2])  # بازسازی داده‌ها با تعداد ویژگی‌ها\n",
        "predicted_data = scaler.inverse_transform(predicted_data)  # بازگرداندن داده‌ها به مقیاس اصلی\n",
        "predicted_candlesticks = predicted_data[:, :4]\n"
      ],
      "metadata": {
        "id": "a8n9KJrqXLP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mplfinance"
      ],
      "metadata": {
        "id": "DpNj0zGoXLN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# محاسبه درصد بدنه کندل‌ها\n",
        "percentage_bodies = np.abs(predicted_candlesticks[:, 3] - predicted_candlesticks[:, 0]) / np.maximum(\n",
        "    predicted_candlesticks[:, 3], predicted_candlesticks[:, 0])\n",
        "\n",
        "percentage_high_low = np.abs(predicted_candlesticks[:, 1] - predicted_candlesticks[:, 2]) / np.maximum(\n",
        "    predicted_candlesticks[:, 1], predicted_candlesticks[:, 2])\n",
        "# تبدیل numpy array به pandas DataFrame\n",
        "df_predicted = pd.DataFrame(predicted_candlesticks, columns=['Open', 'High', 'Low', 'Close'])\n",
        "\n",
        "# اضافه کردن درصد بدنه و درصد High-Low به DataFrame\n",
        "df_predicted['Body Percentage'] = percentage_bodies\n",
        "df_predicted['High-Low Percentage'] = percentage_high_low\n",
        "\n",
        "# ایجاد ستون تاریخ برای 30 روز آینده\n",
        "df_predicted['Date'] = pd.date_range(start='2024-10-05', periods=len(df_predicted), freq='D')\n",
        "\n",
        "# تنظیم ستون 'Date' به عنوان ایندکس DataFrame\n",
        "df_predicted.set_index('Date', inplace=True)"
      ],
      "metadata": {
        "id": "U2nyylZ4XLLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_predicted.to_csv('predicted_candlesticks.csv')\n",
        "\n",
        "print(\"داده‌های پیش‌بینی شده در فایل 'predicted_candlesticks.csv' ذخیره شد.\")\n"
      ],
      "metadata": {
        "id": "gCllaKGTXoG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# نمایش کندل‌های پیش‌بینی شده برای 30 روز آینده\n",
        "print(\"Predicted Candlesticks for the Next 30 Days:\")\n",
        "\n",
        "for i, candlestick in enumerate(predicted_candlesticks):\n",
        "    open_price = candlestick[0]\n",
        "    high_price = candlestick[1]\n",
        "    low_price = candlestick[2]\n",
        "    close_price = candlestick[3]\n",
        "\n",
        "    # محاسبه درصد بدنه کندل\n",
        "    body_percentage = abs(close_price - open_price) / max(close_price, open_price)\n",
        "\n",
        "    # محاسبه درصد سایه بالا\n",
        "    upper_shadow_percentage = (high_price - max(open_price, close_price)) / high_price\n",
        "\n",
        "    # محاسبه درصد سایه پایین\n",
        "    lower_shadow_percentage = (min(open_price, close_price) - low_price) / low_price\n",
        "\n",
        "    # نمایش اطلاعات کندل\n",
        "    print(f\"Day {i+1}: Open: {open_price:.2f}, High: {high_price:.2f}, Low: {low_price:.2f}, Close: {close_price:.2f}, \"\n",
        "          f\"Body Percentage: {body_percentage:.4f}, Upper Shadow Percentage: {upper_shadow_percentage:.4f}, Lower Shadow Percentage: {lower_shadow_percentage:.4f}\")\n"
      ],
      "metadata": {
        "id": "p8mkaAeWXoE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# نمایش پیش‌بینی کندل‌های 30 روز آینده\n",
        "print(\"Predicted Candlesticks for the Next 30 Days:\")\n",
        "for i, candlestick in enumerate(predicted_data[:, :4]):  # فقط 4 ستون اول (Open, High, Low, Close)\n",
        "    print(\n",
        "        f\"Day {i+1}: Open: {candlestick[0]}, High: {candlestick[1]}, Low: {candlestick[2]}, Close: {candlestick[3]}\"\n",
        "    )\n",
        "\n",
        "# خواندن داده‌ها از فایل CSV\n",
        "df = pd.read_csv('predicted_candlesticks.csv')\n",
        "\n",
        "# اطمینان از تبدیل صحیح داده‌ها\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# انتخاب ستون‌های مرتبط با نمودار کندل (Open, High, Low, Close)\n",
        "df_candlestick = df[['Date', 'Open', 'High', 'Low', 'Close']]\n",
        "\n",
        "# تنظیم ستون 'Date' به عنوان ایندکس برای رسم نمودار\n",
        "df_candlestick.set_index('Date', inplace=True)\n",
        "\n",
        "# ادامه کد رسم نمودار کندل\n",
        "import mplfinance as mpf\n",
        "mpf.plot(df_candlestick, type='candle', style='charles',\n",
        "         title='Predicted Candlesticks for the Next 30 Days', volume=False)\n"
      ],
      "metadata": {
        "id": "wHL-UcmaXoCR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}